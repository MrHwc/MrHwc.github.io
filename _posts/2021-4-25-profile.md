---
layout:
title: Pytorch模型加载
description: "Chen"
modified: 2021-4-25
tags: pytorch
--- 
# nn.DataParallel模型加载  
首先说明`nn.DataParallel`如何使用，使用事例如下：
```
model = model.to(device) 
model = nn.DataParallel(model)
```
多GPU下保存模型参数样例如下：  
```
torch.save(model.module.state_dict(), "model.pth")
```
在实际调整代码时可能忘记使用上述代码进行保存，直接使用了以下代码进行保存(参数加载时会有问题)：
```
torch.save(model.state_dict(), "model.pth")
```
直接保存`model.state_dict()`，加载模型参数时会报错，因为参数字典中含有`module`，可使用以下方法进行加载：
```
model = Net().to(device)
model = nn.DataParallel(model)  # 将模型放在多卡上
model.eval()
state_dict = torch.load(model_path)  # 加载 含有"module"的模型参数
model.load_state_dict(state_dict)
```

# 冻结部分层  
在pytorch中冻结部分层，可以使用以下代码输出层的编号：
```
    for num, (name, param) in enumerate(model.named_parameters()):
        print(num, name, param.shape)
```
根据层的编号，冻结指定编号的层：
```
    layer_num = torch.arange(88, 104)  
    for num, param in enumerate(model.parameters(), 1):
        if num in layer_num:
            param.requires_grad = False
```
